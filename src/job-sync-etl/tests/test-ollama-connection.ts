import "dotenv/config";
import { config, ollamaModels } from "@/config";
import { OllamaEnrichmentService } from "@/job-sync-etl/services/ollama-enrichment";

async function testOllamaConnection() {
  console.log("ğŸ§ª Testing Remote Ollama Connection...");
  console.log(`ğŸ”— Connecting to: ${config.ollamaUrl}`);
  console.log(`ğŸ“‹ Expected models: ${ollamaModels.join(", ")}`);

  const service = new OllamaEnrichmentService();

  try {
    // Test basic connection
    console.log("\nğŸ” Step 1: Testing basic connection...");
    const connectionTest = await service.testConnection();

    if (!connectionTest.connected) {
      console.error("âŒ Failed to connect to remote Ollama instance");
      console.error(`ğŸ“ Error: ${connectionTest.error}`);
      console.error("\nğŸ› ï¸  Troubleshooting:");
      console.error("1. Verify OLLAMA_URL is correct in your .env file");
      console.error("2. Ensure the remote Ollama service is running");
      console.error("3. Check network connectivity");
      console.error("4. Verify firewall settings allow connections");
      return;
    }

    console.log("âœ… Successfully connected to remote Ollama instance");
    console.log(`ğŸ“‹ Available models: ${connectionTest.models.join(", ")}`);

    // Test model initialization
    console.log("\nğŸ” Step 2: Testing model initialization...");
    await service.initialize();

    const modelStatus = await service.getModelStatus();
    console.log("\nğŸ“Š Model Status Report:");
    modelStatus.forEach(({ model, available }) => {
      console.log(
        `  ${available ? "âœ…" : "âŒ"} ${model} ${
          available ? "(Available)" : "(Not available)"
        }`
      );
    });

    const availableCount = modelStatus.filter((m) => m.available).length;
    if (availableCount === 0) {
      console.error(
        "\nâŒ None of the configured models are available on the remote instance"
      );
      console.error(
        "ğŸ› ï¸  Please install the required models on the remote machine:"
      );
      ollamaModels.forEach((model) => {
        console.error(`   ollama pull ${model}`);
      });
      return;
    }

    console.log(
      `\nâœ… ${availableCount}/${ollamaModels.length} configured models are available`
    );

    // Test health check
    console.log("\nğŸ” Step 3: Testing health check...");
    const isHealthy = await service.isHealthy();
    console.log(
      `ğŸ¥ Health Status: ${isHealthy ? "âœ… Healthy" : "âŒ Unhealthy"}`
    );

    if (isHealthy) {
      console.log("\nğŸ‰ Remote Ollama connection test completed successfully!");
      console.log("âœ… Ready to proceed with the migration");
    } else {
      console.error("\nâŒ Health check failed - service may not be ready");
    }
  } catch (error) {
    console.error("âŒ Connection test failed:", error);
    console.error("\nğŸ› ï¸  Common issues and solutions:");
    console.error(
      "1. OLLAMA_URL format should be: http://hostname:port (usually port 11434)"
    );
    console.error("2. Remote Ollama service must be running: `ollama serve`");
    console.error("3. If using Docker, ensure ports are properly exposed");
    console.error("4. Check if the remote machine allows external connections");
  }
}

// Run the test
testOllamaConnection().catch(console.error);
